{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matsunori39/AI-and-Machine-Learning-for-Coders/blob/main/AI_and_Machine_Learning_for_Coders.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wveHx2eBHtcI"
      },
      "source": [
        "https://www.oreilly.co.jp/books/9784873119809/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QC3Fkr4KHrJ7"
      },
      "source": [
        "# Part1: Model Building"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfSgLE9_H_C6"
      },
      "source": [
        "## Chapter 1: Overview of TensorFlow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VVYlXpDIYEX"
      },
      "source": [
        "### 1.6 Getting Started in Machine Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3T33vfGIg5W",
        "outputId": "bc337aeb-872a-4c21-933d-7e4e5f57b725"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "1/1 [==============================] - 1s 765ms/step - loss: 4.1871\n",
            "Epoch 2/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 3.4617\n",
            "Epoch 3/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.8877\n",
            "Epoch 4/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.4326\n",
            "Epoch 5/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.0713\n",
            "Epoch 6/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.7838\n",
            "Epoch 7/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.5545\n",
            "Epoch 8/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.3709\n",
            "Epoch 9/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.2235\n",
            "Epoch 10/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.1045\n",
            "Epoch 11/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.0080\n",
            "Epoch 12/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.9292\n",
            "Epoch 13/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.8644\n",
            "Epoch 14/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.8107\n",
            "Epoch 15/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.7657\n",
            "Epoch 16/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.7278\n",
            "Epoch 17/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6953\n",
            "Epoch 18/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6672\n",
            "Epoch 19/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6427\n",
            "Epoch 20/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6210\n",
            "Epoch 21/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.6015\n",
            "Epoch 22/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.5839\n",
            "Epoch 23/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.5677\n",
            "Epoch 24/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.5528\n",
            "Epoch 25/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.5389\n",
            "Epoch 26/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.5258\n",
            "Epoch 27/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5134\n",
            "Epoch 28/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5016\n",
            "Epoch 29/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4903\n",
            "Epoch 30/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4795\n",
            "Epoch 31/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4690\n",
            "Epoch 32/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4589\n",
            "Epoch 33/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4491\n",
            "Epoch 34/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4396\n",
            "Epoch 35/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4303\n",
            "Epoch 36/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.4213\n",
            "Epoch 37/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.4125\n",
            "Epoch 38/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.4039\n",
            "Epoch 39/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3955\n",
            "Epoch 40/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.3873\n",
            "Epoch 41/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3793\n",
            "Epoch 42/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3715\n",
            "Epoch 43/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.3638\n",
            "Epoch 44/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3563\n",
            "Epoch 45/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.3490\n",
            "Epoch 46/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3418\n",
            "Epoch 47/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3347\n",
            "Epoch 48/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3279\n",
            "Epoch 49/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3211\n",
            "Epoch 50/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3145\n",
            "Epoch 51/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3081\n",
            "Epoch 52/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.3017\n",
            "Epoch 53/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2955\n",
            "Epoch 54/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.2894\n",
            "Epoch 55/500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.2835\n",
            "Epoch 56/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2777\n",
            "Epoch 57/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2720\n",
            "Epoch 58/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2664\n",
            "Epoch 59/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2609\n",
            "Epoch 60/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.2555\n",
            "Epoch 61/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2503\n",
            "Epoch 62/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2452\n",
            "Epoch 63/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.2401\n",
            "Epoch 64/500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.2352\n",
            "Epoch 65/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.2304\n",
            "Epoch 66/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2256\n",
            "Epoch 67/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.2210\n",
            "Epoch 68/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2165\n",
            "Epoch 69/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2120\n",
            "Epoch 70/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2077\n",
            "Epoch 71/500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.2034\n",
            "Epoch 72/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1992\n",
            "Epoch 73/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1951\n",
            "Epoch 74/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1911\n",
            "Epoch 75/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1872\n",
            "Epoch 76/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1833\n",
            "Epoch 77/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1796\n",
            "Epoch 78/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1759\n",
            "Epoch 79/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1723\n",
            "Epoch 80/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1687\n",
            "Epoch 81/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1653\n",
            "Epoch 82/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1619\n",
            "Epoch 83/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1585\n",
            "Epoch 84/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1553\n",
            "Epoch 85/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1521\n",
            "Epoch 86/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1490\n",
            "Epoch 87/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1459\n",
            "Epoch 88/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1429\n",
            "Epoch 89/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1400\n",
            "Epoch 90/500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.1371\n",
            "Epoch 91/500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.1343\n",
            "Epoch 92/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.1315\n",
            "Epoch 93/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1288\n",
            "Epoch 94/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1262\n",
            "Epoch 95/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1236\n",
            "Epoch 96/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1211\n",
            "Epoch 97/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1186\n",
            "Epoch 98/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.1161\n",
            "Epoch 99/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1137\n",
            "Epoch 100/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1114\n",
            "Epoch 101/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.1091\n",
            "Epoch 102/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1069\n",
            "Epoch 103/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1047\n",
            "Epoch 104/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1025\n",
            "Epoch 105/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1004\n",
            "Epoch 106/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0984\n",
            "Epoch 107/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0963\n",
            "Epoch 108/500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0944\n",
            "Epoch 109/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0924\n",
            "Epoch 110/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0905\n",
            "Epoch 111/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0887\n",
            "Epoch 112/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0868\n",
            "Epoch 113/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0851\n",
            "Epoch 114/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0833\n",
            "Epoch 115/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0816\n",
            "Epoch 116/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0799\n",
            "Epoch 117/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0783\n",
            "Epoch 118/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0767\n",
            "Epoch 119/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0751\n",
            "Epoch 120/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0736\n",
            "Epoch 121/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0721\n",
            "Epoch 122/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0706\n",
            "Epoch 123/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0691\n",
            "Epoch 124/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0677\n",
            "Epoch 125/500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0663\n",
            "Epoch 126/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0649\n",
            "Epoch 127/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0636\n",
            "Epoch 128/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0623\n",
            "Epoch 129/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0610\n",
            "Epoch 130/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0598\n",
            "Epoch 131/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0585\n",
            "Epoch 132/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0573\n",
            "Epoch 133/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0562\n",
            "Epoch 134/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0550\n",
            "Epoch 135/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0539\n",
            "Epoch 136/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0528\n",
            "Epoch 137/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0517\n",
            "Epoch 138/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0506\n",
            "Epoch 139/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0496\n",
            "Epoch 140/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0486\n",
            "Epoch 141/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0476\n",
            "Epoch 142/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0466\n",
            "Epoch 143/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0456\n",
            "Epoch 144/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0447\n",
            "Epoch 145/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0438\n",
            "Epoch 146/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0429\n",
            "Epoch 147/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0420\n",
            "Epoch 148/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0411\n",
            "Epoch 149/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0403\n",
            "Epoch 150/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0395\n",
            "Epoch 151/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0387\n",
            "Epoch 152/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0379\n",
            "Epoch 153/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0371\n",
            "Epoch 154/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0363\n",
            "Epoch 155/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0356\n",
            "Epoch 156/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0348\n",
            "Epoch 157/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0341\n",
            "Epoch 158/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0334\n",
            "Epoch 159/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0327\n",
            "Epoch 160/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0321\n",
            "Epoch 161/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0314\n",
            "Epoch 162/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0308\n",
            "Epoch 163/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0301\n",
            "Epoch 164/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0295\n",
            "Epoch 165/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0289\n",
            "Epoch 166/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0283\n",
            "Epoch 167/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0277\n",
            "Epoch 168/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0272\n",
            "Epoch 169/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0266\n",
            "Epoch 170/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0261\n",
            "Epoch 171/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0255\n",
            "Epoch 172/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0250\n",
            "Epoch 173/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0245\n",
            "Epoch 174/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0240\n",
            "Epoch 175/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0235\n",
            "Epoch 176/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0230\n",
            "Epoch 177/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0225\n",
            "Epoch 178/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0221\n",
            "Epoch 179/500\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0216\n",
            "Epoch 180/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0212\n",
            "Epoch 181/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0207\n",
            "Epoch 182/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0203\n",
            "Epoch 183/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0199\n",
            "Epoch 184/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0195\n",
            "Epoch 185/500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0191\n",
            "Epoch 186/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0187\n",
            "Epoch 187/500\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0183\n",
            "Epoch 188/500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0179\n",
            "Epoch 189/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0176\n",
            "Epoch 190/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0172\n",
            "Epoch 191/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0169\n",
            "Epoch 192/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0165\n",
            "Epoch 193/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0162\n",
            "Epoch 194/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0158\n",
            "Epoch 195/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0155\n",
            "Epoch 196/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0152\n",
            "Epoch 197/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0149\n",
            "Epoch 198/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0146\n",
            "Epoch 199/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0143\n",
            "Epoch 200/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0140\n",
            "Epoch 201/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0137\n",
            "Epoch 202/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0134\n",
            "Epoch 203/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0131\n",
            "Epoch 204/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0129\n",
            "Epoch 205/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0126\n",
            "Epoch 206/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0123\n",
            "Epoch 207/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0121\n",
            "Epoch 208/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0118\n",
            "Epoch 209/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0116\n",
            "Epoch 210/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0114\n",
            "Epoch 211/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0111\n",
            "Epoch 212/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0109\n",
            "Epoch 213/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0107\n",
            "Epoch 214/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0105\n",
            "Epoch 215/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0102\n",
            "Epoch 216/500\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 0.0100\n",
            "Epoch 217/500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0098\n",
            "Epoch 218/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0096\n",
            "Epoch 219/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0094\n",
            "Epoch 220/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0092\n",
            "Epoch 221/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0090\n",
            "Epoch 222/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0089\n",
            "Epoch 223/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0087\n",
            "Epoch 224/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0085\n",
            "Epoch 225/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0083\n",
            "Epoch 226/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0082\n",
            "Epoch 227/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0080\n",
            "Epoch 228/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0078\n",
            "Epoch 229/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0077\n",
            "Epoch 230/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0075\n",
            "Epoch 231/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0073\n",
            "Epoch 232/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0072\n",
            "Epoch 233/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0070\n",
            "Epoch 234/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0069\n",
            "Epoch 235/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0068\n",
            "Epoch 236/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0066\n",
            "Epoch 237/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0065\n",
            "Epoch 238/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0064\n",
            "Epoch 239/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0062\n",
            "Epoch 240/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0061\n",
            "Epoch 241/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0060\n",
            "Epoch 242/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0058\n",
            "Epoch 243/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0057\n",
            "Epoch 244/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0056\n",
            "Epoch 245/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0055\n",
            "Epoch 246/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0054\n",
            "Epoch 247/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0053\n",
            "Epoch 248/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0052\n",
            "Epoch 249/500\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0051\n",
            "Epoch 250/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0050\n",
            "Epoch 251/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0049\n",
            "Epoch 252/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0048\n",
            "Epoch 253/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0047\n",
            "Epoch 254/500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0046\n",
            "Epoch 255/500\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0045\n",
            "Epoch 256/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0044\n",
            "Epoch 257/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0043\n",
            "Epoch 258/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0042\n",
            "Epoch 259/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0041\n",
            "Epoch 260/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0040\n",
            "Epoch 261/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0039\n",
            "Epoch 262/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0039\n",
            "Epoch 263/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0038\n",
            "Epoch 264/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0037\n",
            "Epoch 265/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0036\n",
            "Epoch 266/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0036\n",
            "Epoch 267/500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0035\n",
            "Epoch 268/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0034\n",
            "Epoch 269/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0033\n",
            "Epoch 270/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0033\n",
            "Epoch 271/500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0032\n",
            "Epoch 272/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0031\n",
            "Epoch 273/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0031\n",
            "Epoch 274/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0030\n",
            "Epoch 275/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0029\n",
            "Epoch 276/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0029\n",
            "Epoch 277/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0028\n",
            "Epoch 278/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0028\n",
            "Epoch 279/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0027\n",
            "Epoch 280/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0027\n",
            "Epoch 281/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0026\n",
            "Epoch 282/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0025\n",
            "Epoch 283/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0025\n",
            "Epoch 284/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0024\n",
            "Epoch 285/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0024\n",
            "Epoch 286/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0023\n",
            "Epoch 287/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0023\n",
            "Epoch 288/500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0023\n",
            "Epoch 289/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0022\n",
            "Epoch 290/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0022\n",
            "Epoch 291/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0021\n",
            "Epoch 292/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0021\n",
            "Epoch 293/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0020\n",
            "Epoch 294/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0020\n",
            "Epoch 295/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0019\n",
            "Epoch 296/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0019\n",
            "Epoch 297/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0019\n",
            "Epoch 298/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0018\n",
            "Epoch 299/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0018\n",
            "Epoch 300/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0018\n",
            "Epoch 301/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0017\n",
            "Epoch 302/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0017\n",
            "Epoch 303/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0016\n",
            "Epoch 304/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0016\n",
            "Epoch 305/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0016\n",
            "Epoch 306/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0015\n",
            "Epoch 307/500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0015\n",
            "Epoch 308/500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0015\n",
            "Epoch 309/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0015\n",
            "Epoch 310/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0014\n",
            "Epoch 311/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0014\n",
            "Epoch 312/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0014\n",
            "Epoch 313/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0013\n",
            "Epoch 314/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0013\n",
            "Epoch 315/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0013\n",
            "Epoch 316/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0013\n",
            "Epoch 317/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0012\n",
            "Epoch 318/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0012\n",
            "Epoch 319/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0012\n",
            "Epoch 320/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0012\n",
            "Epoch 321/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0011\n",
            "Epoch 322/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0011\n",
            "Epoch 323/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0011\n",
            "Epoch 324/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0011\n",
            "Epoch 325/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0010\n",
            "Epoch 326/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0010\n",
            "Epoch 327/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0010\n",
            "Epoch 328/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.8137e-04\n",
            "Epoch 329/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.6121e-04\n",
            "Epoch 330/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.4147e-04\n",
            "Epoch 331/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 9.2213e-04\n",
            "Epoch 332/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 9.0319e-04\n",
            "Epoch 333/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 8.8464e-04\n",
            "Epoch 334/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 8.6647e-04\n",
            "Epoch 335/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.4867e-04\n",
            "Epoch 336/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3124e-04\n",
            "Epoch 337/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.1416e-04\n",
            "Epoch 338/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.9744e-04\n",
            "Epoch 339/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 7.8106e-04\n",
            "Epoch 340/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 7.6502e-04\n",
            "Epoch 341/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 7.4930e-04\n",
            "Epoch 342/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.3391e-04\n",
            "Epoch 343/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 7.1883e-04\n",
            "Epoch 344/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.0407e-04\n",
            "Epoch 345/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.8961e-04\n",
            "Epoch 346/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 6.7544e-04\n",
            "Epoch 347/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 6.6157e-04\n",
            "Epoch 348/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 6.4798e-04\n",
            "Epoch 349/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.3467e-04\n",
            "Epoch 350/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.2163e-04\n",
            "Epoch 351/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 6.0886e-04\n",
            "Epoch 352/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 5.9636e-04\n",
            "Epoch 353/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 5.8411e-04\n",
            "Epoch 354/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 5.7211e-04\n",
            "Epoch 355/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.6036e-04\n",
            "Epoch 356/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.4885e-04\n",
            "Epoch 357/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.3758e-04\n",
            "Epoch 358/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.2653e-04\n",
            "Epoch 359/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.1572e-04\n",
            "Epoch 360/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.0513e-04\n",
            "Epoch 361/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.9475e-04\n",
            "Epoch 362/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 4.8459e-04\n",
            "Epoch 363/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.7463e-04\n",
            "Epoch 364/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.6488e-04\n",
            "Epoch 365/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 4.5533e-04\n",
            "Epoch 366/500\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 4.4598e-04\n",
            "Epoch 367/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 4.3682e-04\n",
            "Epoch 368/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.2785e-04\n",
            "Epoch 369/500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 4.1906e-04\n",
            "Epoch 370/500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 4.1045e-04\n",
            "Epoch 371/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 4.0202e-04\n",
            "Epoch 372/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.9376e-04\n",
            "Epoch 373/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.8567e-04\n",
            "Epoch 374/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.7775e-04\n",
            "Epoch 375/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.7000e-04\n",
            "Epoch 376/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 3.6239e-04\n",
            "Epoch 377/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.5495e-04\n",
            "Epoch 378/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.4766e-04\n",
            "Epoch 379/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 3.4052e-04\n",
            "Epoch 380/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 3.3352e-04\n",
            "Epoch 381/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.2667e-04\n",
            "Epoch 382/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.1996e-04\n",
            "Epoch 383/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.1339e-04\n",
            "Epoch 384/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.0695e-04\n",
            "Epoch 385/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.0065e-04\n",
            "Epoch 386/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.9447e-04\n",
            "Epoch 387/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.8842e-04\n",
            "Epoch 388/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.8250e-04\n",
            "Epoch 389/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.7669e-04\n",
            "Epoch 390/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.7101e-04\n",
            "Epoch 391/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.6545e-04\n",
            "Epoch 392/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.5999e-04\n",
            "Epoch 393/500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.5465e-04\n",
            "Epoch 394/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.4942e-04\n",
            "Epoch 395/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.4430e-04\n",
            "Epoch 396/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.3928e-04\n",
            "Epoch 397/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.3437e-04\n",
            "Epoch 398/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.2955e-04\n",
            "Epoch 399/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.2484e-04\n",
            "Epoch 400/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.2022e-04\n",
            "Epoch 401/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.1569e-04\n",
            "Epoch 402/500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.1126e-04\n",
            "Epoch 403/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.0692e-04\n",
            "Epoch 404/500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.0268e-04\n",
            "Epoch 405/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.9851e-04\n",
            "Epoch 406/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.9444e-04\n",
            "Epoch 407/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.9044e-04\n",
            "Epoch 408/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.8653e-04\n",
            "Epoch 409/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 1.8270e-04\n",
            "Epoch 410/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.7895e-04\n",
            "Epoch 411/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.7527e-04\n",
            "Epoch 412/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.7167e-04\n",
            "Epoch 413/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.6814e-04\n",
            "Epoch 414/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.6469e-04\n",
            "Epoch 415/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.6131e-04\n",
            "Epoch 416/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.5799e-04\n",
            "Epoch 417/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.5475e-04\n",
            "Epoch 418/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.5157e-04\n",
            "Epoch 419/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.4846e-04\n",
            "Epoch 420/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.4541e-04\n",
            "Epoch 421/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.4242e-04\n",
            "Epoch 422/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.3950e-04\n",
            "Epoch 423/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.3663e-04\n",
            "Epoch 424/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.3382e-04\n",
            "Epoch 425/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.3108e-04\n",
            "Epoch 426/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.2838e-04\n",
            "Epoch 427/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.2575e-04\n",
            "Epoch 428/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.2316e-04\n",
            "Epoch 429/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.2063e-04\n",
            "Epoch 430/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.1815e-04\n",
            "Epoch 431/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.1573e-04\n",
            "Epoch 432/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.1335e-04\n",
            "Epoch 433/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.1102e-04\n",
            "Epoch 434/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0874e-04\n",
            "Epoch 435/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0651e-04\n",
            "Epoch 436/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.0432e-04\n",
            "Epoch 437/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0218e-04\n",
            "Epoch 438/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0008e-04\n",
            "Epoch 439/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.8024e-05\n",
            "Epoch 440/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 9.6011e-05\n",
            "Epoch 441/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 9.4039e-05\n",
            "Epoch 442/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.2107e-05\n",
            "Epoch 443/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.0215e-05\n",
            "Epoch 444/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.8362e-05\n",
            "Epoch 445/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.6546e-05\n",
            "Epoch 446/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 8.4770e-05\n",
            "Epoch 447/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3028e-05\n",
            "Epoch 448/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.1322e-05\n",
            "Epoch 449/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.9653e-05\n",
            "Epoch 450/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.8016e-05\n",
            "Epoch 451/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.6414e-05\n",
            "Epoch 452/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.4844e-05\n",
            "Epoch 453/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.3306e-05\n",
            "Epoch 454/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1801e-05\n",
            "Epoch 455/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.0326e-05\n",
            "Epoch 456/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.8882e-05\n",
            "Epoch 457/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.7466e-05\n",
            "Epoch 458/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.6082e-05\n",
            "Epoch 459/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.4724e-05\n",
            "Epoch 460/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.3394e-05\n",
            "Epoch 461/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.2092e-05\n",
            "Epoch 462/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.0816e-05\n",
            "Epoch 463/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.9568e-05\n",
            "Epoch 464/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.8344e-05\n",
            "Epoch 465/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.7146e-05\n",
            "Epoch 466/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.5971e-05\n",
            "Epoch 467/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.4822e-05\n",
            "Epoch 468/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.3695e-05\n",
            "Epoch 469/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.2592e-05\n",
            "Epoch 470/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.1512e-05\n",
            "Epoch 471/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.0454e-05\n",
            "Epoch 472/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 4.9418e-05\n",
            "Epoch 473/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.8403e-05\n",
            "Epoch 474/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.7409e-05\n",
            "Epoch 475/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.6435e-05\n",
            "Epoch 476/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 4.5481e-05\n",
            "Epoch 477/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 4.4547e-05\n",
            "Epoch 478/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.3632e-05\n",
            "Epoch 479/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.2736e-05\n",
            "Epoch 480/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 4.1858e-05\n",
            "Epoch 481/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.0998e-05\n",
            "Epoch 482/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 4.0157e-05\n",
            "Epoch 483/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.9332e-05\n",
            "Epoch 484/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.8524e-05\n",
            "Epoch 485/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.7732e-05\n",
            "Epoch 486/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.6957e-05\n",
            "Epoch 487/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.6198e-05\n",
            "Epoch 488/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.5455e-05\n",
            "Epoch 489/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.4726e-05\n",
            "Epoch 490/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.4013e-05\n",
            "Epoch 491/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.3314e-05\n",
            "Epoch 492/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.2630e-05\n",
            "Epoch 493/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.1960e-05\n",
            "Epoch 494/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.1304e-05\n",
            "Epoch 495/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.0660e-05\n",
            "Epoch 496/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.0031e-05\n",
            "Epoch 497/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.9414e-05\n",
            "Epoch 498/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.8810e-05\n",
            "Epoch 499/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.8219e-05\n",
            "Epoch 500/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.7639e-05\n",
            "[[18.984661]]\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "model = Sequential([Dense(units=1, input_shape=[1])])\n",
        "model.compile(optimizer='sgd', loss='mean_squared_error')\n",
        "\n",
        "xs = np.array([-1.0, 0.0, 1.0, 2.0, 3.0, 4.0], dtype=float)\n",
        "ys = np.array([-3.0, -1.0, 1.0, 3.0, 5.0, 7.0], dtype=float)\n",
        "\n",
        "model.fit(xs, ys, epochs=500)\n",
        "\n",
        "print(model.predict([10.0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2YENPfdOJUC2",
        "outputId": "ff91b689-067c-4118-9267-d8f4782c0864"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "1/1 [==============================] - 1s 787ms/step - loss: 60.3013\n",
            "Epoch 2/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 47.8744\n",
            "Epoch 3/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 38.0887\n",
            "Epoch 4/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 30.3810\n",
            "Epoch 5/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 24.3085\n",
            "Epoch 6/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 19.5226\n",
            "Epoch 7/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 15.7491\n",
            "Epoch 8/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 12.7723\n",
            "Epoch 9/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 10.4225\n",
            "Epoch 10/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.5660\n",
            "Epoch 11/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.0980\n",
            "Epoch 12/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.9356\n",
            "Epoch 13/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.0139\n",
            "Epoch 14/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.2817\n",
            "Epoch 15/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.6987\n",
            "Epoch 16/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.2332\n",
            "Epoch 17/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.8604\n",
            "Epoch 18/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.5605\n",
            "Epoch 19/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.3183\n",
            "Epoch 20/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.1214\n",
            "Epoch 21/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.9604\n",
            "Epoch 22/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.8278\n",
            "Epoch 23/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.7176\n",
            "Epoch 24/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.6251\n",
            "Epoch 25/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.5468\n",
            "Epoch 26/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.4796\n",
            "Epoch 27/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.4214\n",
            "Epoch 28/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.3703\n",
            "Epoch 29/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.3249\n",
            "Epoch 30/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.2841\n",
            "Epoch 31/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.2471\n",
            "Epoch 32/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.2131\n",
            "Epoch 33/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.1815\n",
            "Epoch 34/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.1521\n",
            "Epoch 35/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.1243\n",
            "Epoch 36/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.0980\n",
            "Epoch 37/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.0729\n",
            "Epoch 38/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0489\n",
            "Epoch 39/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0258\n",
            "Epoch 40/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0035\n",
            "Epoch 41/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.9819\n",
            "Epoch 42/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.9610\n",
            "Epoch 43/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.9406\n",
            "Epoch 44/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.9208\n",
            "Epoch 45/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.9016\n",
            "Epoch 46/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.8828\n",
            "Epoch 47/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.8644\n",
            "Epoch 48/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.8465\n",
            "Epoch 49/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.8289\n",
            "Epoch 50/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.8118\n",
            "Epoch 51/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.7950\n",
            "Epoch 52/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.7786\n",
            "Epoch 53/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7626\n",
            "Epoch 54/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.7469\n",
            "Epoch 55/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7315\n",
            "Epoch 56/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.7164\n",
            "Epoch 57/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.7017\n",
            "Epoch 58/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6873\n",
            "Epoch 59/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6731\n",
            "Epoch 60/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6593\n",
            "Epoch 61/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6458\n",
            "Epoch 62/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6325\n",
            "Epoch 63/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6195\n",
            "Epoch 64/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6068\n",
            "Epoch 65/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5943\n",
            "Epoch 66/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5821\n",
            "Epoch 67/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5701\n",
            "Epoch 68/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5584\n",
            "Epoch 69/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5469\n",
            "Epoch 70/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5357\n",
            "Epoch 71/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5247\n",
            "Epoch 72/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5139\n",
            "Epoch 73/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5034\n",
            "Epoch 74/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4930\n",
            "Epoch 75/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4829\n",
            "Epoch 76/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4730\n",
            "Epoch 77/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4633\n",
            "Epoch 78/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4538\n",
            "Epoch 79/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4444\n",
            "Epoch 80/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4353\n",
            "Epoch 81/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4264\n",
            "Epoch 82/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4176\n",
            "Epoch 83/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4090\n",
            "Epoch 84/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4006\n",
            "Epoch 85/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.3924\n",
            "Epoch 86/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.3843\n",
            "Epoch 87/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.3764\n",
            "Epoch 88/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.3687\n",
            "Epoch 89/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.3611\n",
            "Epoch 90/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3537\n",
            "Epoch 91/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.3465\n",
            "Epoch 92/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.3393\n",
            "Epoch 93/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3324\n",
            "Epoch 94/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.3255\n",
            "Epoch 95/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3189\n",
            "Epoch 96/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.3123\n",
            "Epoch 97/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.3059\n",
            "Epoch 98/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2996\n",
            "Epoch 99/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2934\n",
            "Epoch 100/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2874\n",
            "Epoch 101/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2815\n",
            "Epoch 102/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2757\n",
            "Epoch 103/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2701\n",
            "Epoch 104/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2645\n",
            "Epoch 105/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2591\n",
            "Epoch 106/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2538\n",
            "Epoch 107/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2486\n",
            "Epoch 108/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2435\n",
            "Epoch 109/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2384\n",
            "Epoch 110/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2336\n",
            "Epoch 111/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2288\n",
            "Epoch 112/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2241\n",
            "Epoch 113/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2195\n",
            "Epoch 114/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2149\n",
            "Epoch 115/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2105\n",
            "Epoch 116/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2062\n",
            "Epoch 117/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.2020\n",
            "Epoch 118/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1978\n",
            "Epoch 119/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1938\n",
            "Epoch 120/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1898\n",
            "Epoch 121/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1859\n",
            "Epoch 122/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1821\n",
            "Epoch 123/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1783\n",
            "Epoch 124/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1747\n",
            "Epoch 125/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1711\n",
            "Epoch 126/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1676\n",
            "Epoch 127/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1641\n",
            "Epoch 128/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1607\n",
            "Epoch 129/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1574\n",
            "Epoch 130/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1542\n",
            "Epoch 131/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1510\n",
            "Epoch 132/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1479\n",
            "Epoch 133/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1449\n",
            "Epoch 134/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1419\n",
            "Epoch 135/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1390\n",
            "Epoch 136/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1362\n",
            "Epoch 137/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1334\n",
            "Epoch 138/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1306\n",
            "Epoch 139/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1279\n",
            "Epoch 140/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1253\n",
            "Epoch 141/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1227\n",
            "Epoch 142/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1202\n",
            "Epoch 143/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1177\n",
            "Epoch 144/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1153\n",
            "Epoch 145/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1130\n",
            "Epoch 146/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1106\n",
            "Epoch 147/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1084\n",
            "Epoch 148/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1061\n",
            "Epoch 149/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1040\n",
            "Epoch 150/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1018\n",
            "Epoch 151/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0997\n",
            "Epoch 152/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0977\n",
            "Epoch 153/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0957\n",
            "Epoch 154/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0937\n",
            "Epoch 155/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0918\n",
            "Epoch 156/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0899\n",
            "Epoch 157/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0881\n",
            "Epoch 158/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0862\n",
            "Epoch 159/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0845\n",
            "Epoch 160/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0827\n",
            "Epoch 161/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0810\n",
            "Epoch 162/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0794\n",
            "Epoch 163/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0777\n",
            "Epoch 164/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0761\n",
            "Epoch 165/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0746\n",
            "Epoch 166/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0731\n",
            "Epoch 167/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0716\n",
            "Epoch 168/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0701\n",
            "Epoch 169/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0686\n",
            "Epoch 170/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0672\n",
            "Epoch 171/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0659\n",
            "Epoch 172/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0645\n",
            "Epoch 173/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0632\n",
            "Epoch 174/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0619\n",
            "Epoch 175/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0606\n",
            "Epoch 176/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0594\n",
            "Epoch 177/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0581\n",
            "Epoch 178/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0569\n",
            "Epoch 179/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0558\n",
            "Epoch 180/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0546\n",
            "Epoch 181/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0535\n",
            "Epoch 182/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0524\n",
            "Epoch 183/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0513\n",
            "Epoch 184/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0503\n",
            "Epoch 185/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0492\n",
            "Epoch 186/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0482\n",
            "Epoch 187/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0472\n",
            "Epoch 188/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0463\n",
            "Epoch 189/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0453\n",
            "Epoch 190/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0444\n",
            "Epoch 191/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0435\n",
            "Epoch 192/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0426\n",
            "Epoch 193/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0417\n",
            "Epoch 194/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0409\n",
            "Epoch 195/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0400\n",
            "Epoch 196/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0392\n",
            "Epoch 197/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0384\n",
            "Epoch 198/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0376\n",
            "Epoch 199/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0368\n",
            "Epoch 200/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0361\n",
            "Epoch 201/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0353\n",
            "Epoch 202/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0346\n",
            "Epoch 203/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0339\n",
            "Epoch 204/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0332\n",
            "Epoch 205/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0325\n",
            "Epoch 206/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0318\n",
            "Epoch 207/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0312\n",
            "Epoch 208/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0306\n",
            "Epoch 209/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0299\n",
            "Epoch 210/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0293\n",
            "Epoch 211/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0287\n",
            "Epoch 212/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0281\n",
            "Epoch 213/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0275\n",
            "Epoch 214/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0270\n",
            "Epoch 215/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0264\n",
            "Epoch 216/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0259\n",
            "Epoch 217/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0253\n",
            "Epoch 218/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0248\n",
            "Epoch 219/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0243\n",
            "Epoch 220/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0238\n",
            "Epoch 221/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0233\n",
            "Epoch 222/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0228\n",
            "Epoch 223/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0224\n",
            "Epoch 224/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0219\n",
            "Epoch 225/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0215\n",
            "Epoch 226/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0210\n",
            "Epoch 227/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0206\n",
            "Epoch 228/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0202\n",
            "Epoch 229/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0198\n",
            "Epoch 230/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0194\n",
            "Epoch 231/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0190\n",
            "Epoch 232/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0186\n",
            "Epoch 233/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0182\n",
            "Epoch 234/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0178\n",
            "Epoch 235/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0174\n",
            "Epoch 236/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0171\n",
            "Epoch 237/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0167\n",
            "Epoch 238/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0164\n",
            "Epoch 239/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0161\n",
            "Epoch 240/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0157\n",
            "Epoch 241/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0154\n",
            "Epoch 242/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0151\n",
            "Epoch 243/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0148\n",
            "Epoch 244/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0145\n",
            "Epoch 245/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0142\n",
            "Epoch 246/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0139\n",
            "Epoch 247/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0136\n",
            "Epoch 248/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0133\n",
            "Epoch 249/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0130\n",
            "Epoch 250/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0128\n",
            "Epoch 251/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0125\n",
            "Epoch 252/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0123\n",
            "Epoch 253/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0120\n",
            "Epoch 254/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0118\n",
            "Epoch 255/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0115\n",
            "Epoch 256/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0113\n",
            "Epoch 257/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0111\n",
            "Epoch 258/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0108\n",
            "Epoch 259/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0106\n",
            "Epoch 260/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0104\n",
            "Epoch 261/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0102\n",
            "Epoch 262/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0100\n",
            "Epoch 263/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0098\n",
            "Epoch 264/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0096\n",
            "Epoch 265/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0094\n",
            "Epoch 266/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0092\n",
            "Epoch 267/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0090\n",
            "Epoch 268/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0088\n",
            "Epoch 269/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0086\n",
            "Epoch 270/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0084\n",
            "Epoch 271/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0083\n",
            "Epoch 272/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0081\n",
            "Epoch 273/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0079\n",
            "Epoch 274/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0078\n",
            "Epoch 275/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0076\n",
            "Epoch 276/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0074\n",
            "Epoch 277/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0073\n",
            "Epoch 278/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0071\n",
            "Epoch 279/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0070\n",
            "Epoch 280/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0069\n",
            "Epoch 281/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0067\n",
            "Epoch 282/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0066\n",
            "Epoch 283/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0064\n",
            "Epoch 284/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0063\n",
            "Epoch 285/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0062\n",
            "Epoch 286/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0061\n",
            "Epoch 287/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0059\n",
            "Epoch 288/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0058\n",
            "Epoch 289/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0057\n",
            "Epoch 290/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0056\n",
            "Epoch 291/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0055\n",
            "Epoch 292/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0053\n",
            "Epoch 293/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0052\n",
            "Epoch 294/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0051\n",
            "Epoch 295/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0050\n",
            "Epoch 296/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0049\n",
            "Epoch 297/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0048\n",
            "Epoch 298/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0047\n",
            "Epoch 299/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0046\n",
            "Epoch 300/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0045\n",
            "Epoch 301/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0044\n",
            "Epoch 302/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0043\n",
            "Epoch 303/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0043\n",
            "Epoch 304/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0042\n",
            "Epoch 305/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0041\n",
            "Epoch 306/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0040\n",
            "Epoch 307/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0039\n",
            "Epoch 308/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0038\n",
            "Epoch 309/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0038\n",
            "Epoch 310/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0037\n",
            "Epoch 311/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0036\n",
            "Epoch 312/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0035\n",
            "Epoch 313/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0035\n",
            "Epoch 314/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0034\n",
            "Epoch 315/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0033\n",
            "Epoch 316/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0032\n",
            "Epoch 317/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0032\n",
            "Epoch 318/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0031\n",
            "Epoch 319/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0031\n",
            "Epoch 320/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0030\n",
            "Epoch 321/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0029\n",
            "Epoch 322/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0029\n",
            "Epoch 323/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0028\n",
            "Epoch 324/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0028\n",
            "Epoch 325/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0027\n",
            "Epoch 326/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0026\n",
            "Epoch 327/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0026\n",
            "Epoch 328/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0025\n",
            "Epoch 329/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0025\n",
            "Epoch 330/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0024\n",
            "Epoch 331/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0024\n",
            "Epoch 332/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0023\n",
            "Epoch 333/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0023\n",
            "Epoch 334/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0022\n",
            "Epoch 335/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0022\n",
            "Epoch 336/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0021\n",
            "Epoch 337/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0021\n",
            "Epoch 338/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0021\n",
            "Epoch 339/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0020\n",
            "Epoch 340/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0020\n",
            "Epoch 341/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0019\n",
            "Epoch 342/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0019\n",
            "Epoch 343/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0019\n",
            "Epoch 344/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0018\n",
            "Epoch 345/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0018\n",
            "Epoch 346/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0017\n",
            "Epoch 347/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0017\n",
            "Epoch 348/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0017\n",
            "Epoch 349/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0016\n",
            "Epoch 350/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0016\n",
            "Epoch 351/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0016\n",
            "Epoch 352/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0015\n",
            "Epoch 353/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0015\n",
            "Epoch 354/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0015\n",
            "Epoch 355/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0014\n",
            "Epoch 356/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0014\n",
            "Epoch 357/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0014\n",
            "Epoch 358/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0014\n",
            "Epoch 359/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0013\n",
            "Epoch 360/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0013\n",
            "Epoch 361/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0013\n",
            "Epoch 362/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0013\n",
            "Epoch 363/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0012\n",
            "Epoch 364/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0012\n",
            "Epoch 365/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0012\n",
            "Epoch 366/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0012\n",
            "Epoch 367/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0011\n",
            "Epoch 368/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0011\n",
            "Epoch 369/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0011\n",
            "Epoch 370/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0011\n",
            "Epoch 371/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0010\n",
            "Epoch 372/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0010\n",
            "Epoch 373/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.9498e-04\n",
            "Epoch 374/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 9.7455e-04\n",
            "Epoch 375/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.5453e-04\n",
            "Epoch 376/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 9.3492e-04\n",
            "Epoch 377/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.1572e-04\n",
            "Epoch 378/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.9691e-04\n",
            "Epoch 379/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.7849e-04\n",
            "Epoch 380/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.6044e-04\n",
            "Epoch 381/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.4277e-04\n",
            "Epoch 382/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.2546e-04\n",
            "Epoch 383/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.0850e-04\n",
            "Epoch 384/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.9189e-04\n",
            "Epoch 385/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.7563e-04\n",
            "Epoch 386/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.5970e-04\n",
            "Epoch 387/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.4409e-04\n",
            "Epoch 388/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.2881e-04\n",
            "Epoch 389/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.1384e-04\n",
            "Epoch 390/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.9918e-04\n",
            "Epoch 391/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.8482e-04\n",
            "Epoch 392/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.7075e-04\n",
            "Epoch 393/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.5697e-04\n",
            "Epoch 394/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.4348e-04\n",
            "Epoch 395/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.3026e-04\n",
            "Epoch 396/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.1731e-04\n",
            "Epoch 397/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.0463e-04\n",
            "Epoch 398/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.9221e-04\n",
            "Epoch 399/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.8005e-04\n",
            "Epoch 400/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.6813e-04\n",
            "Epoch 401/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.5647e-04\n",
            "Epoch 402/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.4503e-04\n",
            "Epoch 403/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.3384e-04\n",
            "Epoch 404/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.2287e-04\n",
            "Epoch 405/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.1213e-04\n",
            "Epoch 406/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.0162e-04\n",
            "Epoch 407/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.9131e-04\n",
            "Epoch 408/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.8122e-04\n",
            "Epoch 409/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.7133e-04\n",
            "Epoch 410/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.6165e-04\n",
            "Epoch 411/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.5217e-04\n",
            "Epoch 412/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.4288e-04\n",
            "Epoch 413/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.3378e-04\n",
            "Epoch 414/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.2487e-04\n",
            "Epoch 415/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.1615e-04\n",
            "Epoch 416/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.0760e-04\n",
            "Epoch 417/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.9923e-04\n",
            "Epoch 418/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.9103e-04\n",
            "Epoch 419/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.8299e-04\n",
            "Epoch 420/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.7513e-04\n",
            "Epoch 421/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.6742e-04\n",
            "Epoch 422/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.5987e-04\n",
            "Epoch 423/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.5248e-04\n",
            "Epoch 424/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.4524e-04\n",
            "Epoch 425/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.3815e-04\n",
            "Epoch 426/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.3121e-04\n",
            "Epoch 427/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.2441e-04\n",
            "Epoch 428/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.1774e-04\n",
            "Epoch 429/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.1121e-04\n",
            "Epoch 430/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.0482e-04\n",
            "Epoch 431/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.9856e-04\n",
            "Epoch 432/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.9243e-04\n",
            "Epoch 433/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.8642e-04\n",
            "Epoch 434/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.8054e-04\n",
            "Epoch 435/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.7478e-04\n",
            "Epoch 436/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.6913e-04\n",
            "Epoch 437/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.6360e-04\n",
            "Epoch 438/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.5819e-04\n",
            "Epoch 439/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.5289e-04\n",
            "Epoch 440/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.4769e-04\n",
            "Epoch 441/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.4260e-04\n",
            "Epoch 442/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.3762e-04\n",
            "Epoch 443/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.3274e-04\n",
            "Epoch 444/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.2796e-04\n",
            "Epoch 445/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.2328e-04\n",
            "Epoch 446/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.1869e-04\n",
            "Epoch 447/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.1420e-04\n",
            "Epoch 448/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.0980e-04\n",
            "Epoch 449/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.0549e-04\n",
            "Epoch 450/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.0127e-04\n",
            "Epoch 451/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.9713e-04\n",
            "Epoch 452/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.9308e-04\n",
            "Epoch 453/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.8912e-04\n",
            "Epoch 454/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.8523e-04\n",
            "Epoch 455/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.8143e-04\n",
            "Epoch 456/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.7770e-04\n",
            "Epoch 457/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.7405e-04\n",
            "Epoch 458/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.7048e-04\n",
            "Epoch 459/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.6697e-04\n",
            "Epoch 460/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.6354e-04\n",
            "Epoch 461/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.6019e-04\n",
            "Epoch 462/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.5690e-04\n",
            "Epoch 463/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.5367e-04\n",
            "Epoch 464/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.5052e-04\n",
            "Epoch 465/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.4742e-04\n",
            "Epoch 466/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.4439e-04\n",
            "Epoch 467/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.4143e-04\n",
            "Epoch 468/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.3853e-04\n",
            "Epoch 469/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.3568e-04\n",
            "Epoch 470/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.3289e-04\n",
            "Epoch 471/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.3016e-04\n",
            "Epoch 472/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.2749e-04\n",
            "Epoch 473/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.2487e-04\n",
            "Epoch 474/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.2230e-04\n",
            "Epoch 475/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.1979e-04\n",
            "Epoch 476/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.1733e-04\n",
            "Epoch 477/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.1492e-04\n",
            "Epoch 478/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.1256e-04\n",
            "Epoch 479/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1025e-04\n",
            "Epoch 480/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0799e-04\n",
            "Epoch 481/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0577e-04\n",
            "Epoch 482/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0359e-04\n",
            "Epoch 483/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0147e-04\n",
            "Epoch 484/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.9383e-05\n",
            "Epoch 485/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 9.7341e-05\n",
            "Epoch 486/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 9.5341e-05\n",
            "Epoch 487/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 9.3384e-05\n",
            "Epoch 488/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.1466e-05\n",
            "Epoch 489/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.9586e-05\n",
            "Epoch 490/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.7746e-05\n",
            "Epoch 491/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.5945e-05\n",
            "Epoch 492/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.4178e-05\n",
            "Epoch 493/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.2450e-05\n",
            "Epoch 494/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.0756e-05\n",
            "Epoch 495/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.9097e-05\n",
            "Epoch 496/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.7474e-05\n",
            "Epoch 497/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.5882e-05\n",
            "Epoch 498/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.4324e-05\n",
            "Epoch 499/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.2797e-05\n",
            "Epoch 500/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.1301e-05\n",
            "[[18.975363]]\n",
            "Here is what I learned: [array([[1.9964293]], dtype=float32), array([-0.9889299], dtype=float32)]\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "l0 = Dense(units=1, input_shape=[1])\n",
        "model = Sequential([l0])\n",
        "model.compile(optimizer='sgd', loss='mean_squared_error')\n",
        "\n",
        "xs = np.array([-1.0, 0.0, 1.0, 2.0, 3.0, 4.0], dtype=float)\n",
        "ys = np.array([-3.0, -1.0, 1.0, 3.0, 5.0, 7.0], dtype=float)\n",
        "\n",
        "model.fit(xs, ys, epochs=500)\n",
        "\n",
        "print(model.predict([10.0]))\n",
        "print(\"Here is what I learned: {}\".format(l0.get_weights()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnjWyl-kNCxI"
      },
      "source": [
        "## Chapter 2: Introduction to Computer Vision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5eAjhGmgWZt6"
      },
      "source": [
        "### 2.3 Design of Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eB8StKQEWl-v"
      },
      "source": [
        "#### Entire Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTZOdpg1Wrze",
        "outputId": "2a3f23b0-8c3c-43e1-a535-fa195fe20405"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.4985 - accuracy: 0.8240\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3756 - accuracy: 0.8648\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3394 - accuracy: 0.8759\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3131 - accuracy: 0.8853\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2959 - accuracy: 0.8905\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f735f57c210>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "data = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(training_images, training_labels), (test_images, test_labels) = data.load_data()\n",
        "\n",
        "training_images = training_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "            tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "            tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "            tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "        ])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZoNq0nrGgBGK",
        "outputId": "9b32dd5c-4ebc-45d2-a688-29546baa9bd1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3559 - accuracy: 0.8723\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3558950126171112, 0.8723000288009644]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "model.evaluate(test_images, test_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWPZVlCwgnJI"
      },
      "source": [
        "### 2.5 Investigation of model outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWcpXEY7g_jL",
        "outputId": "843b6ffd-8999-4d3c-87a2-95c069e285fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4.8206437e-07 7.6424120e-09 4.5361693e-07 3.8542067e-10 1.6919839e-07\n",
            " 1.2948061e-02 8.5949594e-08 2.5158888e-02 9.1501730e-05 9.6180034e-01]\n",
            "9\n"
          ]
        }
      ],
      "source": [
        "classifications = model.predict(test_images)\n",
        "print(classifications[0])\n",
        "print(test_labels[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hN4TA9DAVRL5"
      },
      "source": [
        "### 2.6 Increased number of studies - Finding overfitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7XljvVUFWC8r",
        "outputId": "a4bf18fb-7bda-49ad-a3cd-93381f031549"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.5006 - accuracy: 0.8239\n",
            "Epoch 2/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3735 - accuracy: 0.8661\n",
            "Epoch 3/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3344 - accuracy: 0.8787\n",
            "Epoch 4/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3121 - accuracy: 0.8857\n",
            "Epoch 5/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2960 - accuracy: 0.8912\n",
            "Epoch 6/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2786 - accuracy: 0.8968\n",
            "Epoch 7/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2691 - accuracy: 0.9000\n",
            "Epoch 8/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2555 - accuracy: 0.9045\n",
            "Epoch 9/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2459 - accuracy: 0.9079\n",
            "Epoch 10/50\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2384 - accuracy: 0.9110\n",
            "Epoch 11/50\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.2298 - accuracy: 0.9148\n",
            "Epoch 12/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2224 - accuracy: 0.9165\n",
            "Epoch 13/50\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.2153 - accuracy: 0.9193\n",
            "Epoch 14/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2086 - accuracy: 0.9235\n",
            "Epoch 15/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2030 - accuracy: 0.9228\n",
            "Epoch 16/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1962 - accuracy: 0.9258\n",
            "Epoch 17/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1925 - accuracy: 0.9283\n",
            "Epoch 18/50\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1865 - accuracy: 0.9301\n",
            "Epoch 19/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1822 - accuracy: 0.9315\n",
            "Epoch 20/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1788 - accuracy: 0.9327\n",
            "Epoch 21/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1730 - accuracy: 0.9351\n",
            "Epoch 22/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1680 - accuracy: 0.9361\n",
            "Epoch 23/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1642 - accuracy: 0.9385\n",
            "Epoch 24/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1621 - accuracy: 0.9388\n",
            "Epoch 25/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1555 - accuracy: 0.9415\n",
            "Epoch 26/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1534 - accuracy: 0.9428\n",
            "Epoch 27/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1512 - accuracy: 0.9426\n",
            "Epoch 28/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1470 - accuracy: 0.9448\n",
            "Epoch 29/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1426 - accuracy: 0.9459\n",
            "Epoch 30/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1401 - accuracy: 0.9481\n",
            "Epoch 31/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1396 - accuracy: 0.9463\n",
            "Epoch 32/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1364 - accuracy: 0.9482\n",
            "Epoch 33/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1323 - accuracy: 0.9503\n",
            "Epoch 34/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1299 - accuracy: 0.9513\n",
            "Epoch 35/50\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1264 - accuracy: 0.9521\n",
            "Epoch 36/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1268 - accuracy: 0.9528\n",
            "Epoch 37/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1217 - accuracy: 0.9539\n",
            "Epoch 38/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1213 - accuracy: 0.9551\n",
            "Epoch 39/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1171 - accuracy: 0.9563\n",
            "Epoch 40/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1149 - accuracy: 0.9568\n",
            "Epoch 41/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1161 - accuracy: 0.9561\n",
            "Epoch 42/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1138 - accuracy: 0.9571\n",
            "Epoch 43/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1083 - accuracy: 0.9590\n",
            "Epoch 44/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1079 - accuracy: 0.9598\n",
            "Epoch 45/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1056 - accuracy: 0.9601\n",
            "Epoch 46/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1045 - accuracy: 0.9602\n",
            "Epoch 47/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1015 - accuracy: 0.9620\n",
            "Epoch 48/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1010 - accuracy: 0.9623\n",
            "Epoch 49/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0977 - accuracy: 0.9633\n",
            "Epoch 50/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0957 - accuracy: 0.9637\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f735a356090>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "            tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "            tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "            tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "        ])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UuS0jXO4XSxI",
        "outputId": "729a2b38-640c-41d9-a43e-a190701419cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.5042 - accuracy: 0.8872\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5042215585708618, 0.8871999979019165]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "model.evaluate(test_images, test_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2r22zCDMXW7H"
      },
      "source": [
        "### 2.7 Stop Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2YGHIAcUXvef",
        "outputId": "ea677e6c-413e-459e-875e-c6f91b82a681"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5013 - accuracy: 0.8234\n",
            "Epoch 2/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3749 - accuracy: 0.8634\n",
            "Epoch 3/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3384 - accuracy: 0.8766\n",
            "Epoch 4/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3136 - accuracy: 0.8843\n",
            "Epoch 5/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2974 - accuracy: 0.8901\n",
            "Epoch 6/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2839 - accuracy: 0.8953\n",
            "Epoch 7/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2701 - accuracy: 0.8996\n",
            "Epoch 8/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2587 - accuracy: 0.9033\n",
            "Epoch 9/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2504 - accuracy: 0.9070\n",
            "Epoch 10/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2404 - accuracy: 0.9103\n",
            "Epoch 11/50\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2340 - accuracy: 0.9114\n",
            "Epoch 12/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2265 - accuracy: 0.9153\n",
            "Epoch 13/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2190 - accuracy: 0.9176\n",
            "Epoch 14/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2136 - accuracy: 0.9201\n",
            "Epoch 15/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2075 - accuracy: 0.9224\n",
            "Epoch 16/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2004 - accuracy: 0.9237\n",
            "Epoch 17/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1965 - accuracy: 0.9253\n",
            "Epoch 18/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1898 - accuracy: 0.9290\n",
            "Epoch 19/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1884 - accuracy: 0.9296\n",
            "Epoch 20/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1808 - accuracy: 0.9317\n",
            "Epoch 21/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1774 - accuracy: 0.9337\n",
            "Epoch 22/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1715 - accuracy: 0.9348\n",
            "Epoch 23/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1692 - accuracy: 0.9356\n",
            "Epoch 24/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1647 - accuracy: 0.9379\n",
            "Epoch 25/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1603 - accuracy: 0.9396\n",
            "Epoch 26/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1571 - accuracy: 0.9410\n",
            "Epoch 27/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1537 - accuracy: 0.9427\n",
            "Epoch 28/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1507 - accuracy: 0.9432\n",
            "Epoch 29/50\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1450 - accuracy: 0.9454\n",
            "Epoch 30/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1441 - accuracy: 0.9467\n",
            "Epoch 31/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1400 - accuracy: 0.9466\n",
            "Epoch 32/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1374 - accuracy: 0.9480\n",
            "Epoch 33/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1368 - accuracy: 0.9481\n",
            "Epoch 34/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1319 - accuracy: 0.9497\n",
            "Epoch 35/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1307 - accuracy: 0.9499\n",
            "Epoch 36/50\n",
            "1861/1875 [============================>.] - ETA: 0s - loss: 0.1259 - accuracy: 0.9523\n",
            "Reached 95% accuracy so cancelling training!\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1261 - accuracy: 0.9522\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f735a278750>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    if logs.get('accuracy') > 0.95:\n",
        "      print(\"\\nReached 95% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "callbacks = myCallback()\n",
        "\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(training_images, training_labels), (test_images, test_labels) = data.load_data()\n",
        "\n",
        "training_images = training_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "            tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "            tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "            tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "        ])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=50,\n",
        "          callbacks=[callbacks])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9u4hYlqdY_Uj"
      },
      "source": [
        "## Chapter 3 Development from the Basics: Feature Detection in Images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jI6vpTVpzsL"
      },
      "source": [
        "### 3.3 Convolutional Neural Network Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSESPnR3q4AN",
        "outputId": "e46ef93c-d930-4498-eb38-5d98f1a77017"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1875/1875 [==============================] - 89s 47ms/step - loss: 0.4329 - accuracy: 0.8421\n",
            "Epoch 2/50\n",
            "1875/1875 [==============================] - 87s 46ms/step - loss: 0.2895 - accuracy: 0.8944\n",
            "Epoch 3/50\n",
            "1875/1875 [==============================] - 87s 46ms/step - loss: 0.2459 - accuracy: 0.9083\n",
            "Epoch 4/50\n",
            "1875/1875 [==============================] - 86s 46ms/step - loss: 0.2118 - accuracy: 0.9209\n",
            "Epoch 5/50\n",
            "1875/1875 [==============================] - 86s 46ms/step - loss: 0.1855 - accuracy: 0.9299\n",
            "Epoch 6/50\n",
            "1875/1875 [==============================] - 86s 46ms/step - loss: 0.1626 - accuracy: 0.9396\n",
            "Epoch 7/50\n",
            "1875/1875 [==============================] - 86s 46ms/step - loss: 0.1421 - accuracy: 0.9464\n",
            "Epoch 8/50\n",
            "1875/1875 [==============================] - 87s 47ms/step - loss: 0.1254 - accuracy: 0.9532\n",
            "Epoch 9/50\n",
            "1875/1875 [==============================] - 86s 46ms/step - loss: 0.1075 - accuracy: 0.9606\n",
            "Epoch 10/50\n",
            "1875/1875 [==============================] - 86s 46ms/step - loss: 0.0982 - accuracy: 0.9638\n",
            "Epoch 11/50\n",
            "1875/1875 [==============================] - 85s 45ms/step - loss: 0.0826 - accuracy: 0.9694\n",
            "Epoch 12/50\n",
            "1875/1875 [==============================] - 85s 45ms/step - loss: 0.0742 - accuracy: 0.9716\n",
            "Epoch 13/50\n",
            "1875/1875 [==============================] - 86s 46ms/step - loss: 0.0655 - accuracy: 0.9758\n",
            "Epoch 14/50\n",
            "1875/1875 [==============================] - 85s 45ms/step - loss: 0.0586 - accuracy: 0.9776\n",
            "Epoch 15/50\n",
            "1875/1875 [==============================] - 85s 45ms/step - loss: 0.0504 - accuracy: 0.9805\n",
            "Epoch 16/50\n",
            "1875/1875 [==============================] - 85s 46ms/step - loss: 0.0465 - accuracy: 0.9824\n",
            "Epoch 17/50\n",
            "1875/1875 [==============================] - 85s 45ms/step - loss: 0.0447 - accuracy: 0.9833\n",
            "Epoch 18/50\n",
            "1875/1875 [==============================] - 85s 45ms/step - loss: 0.0391 - accuracy: 0.9856\n",
            "Epoch 19/50\n",
            "1875/1875 [==============================] - 85s 46ms/step - loss: 0.0374 - accuracy: 0.9863\n",
            "Epoch 20/50\n",
            "1875/1875 [==============================] - 86s 46ms/step - loss: 0.0343 - accuracy: 0.9876\n",
            "Epoch 21/50\n",
            "1875/1875 [==============================] - 86s 46ms/step - loss: 0.0331 - accuracy: 0.9876\n",
            "Epoch 22/50\n",
            "1875/1875 [==============================] - 86s 46ms/step - loss: 0.0311 - accuracy: 0.9891\n",
            "Epoch 23/50\n",
            "1875/1875 [==============================] - 86s 46ms/step - loss: 0.0284 - accuracy: 0.9895\n",
            "Epoch 24/50\n",
            "1875/1875 [==============================] - 86s 46ms/step - loss: 0.0296 - accuracy: 0.9894\n",
            "Epoch 25/50\n",
            "1875/1875 [==============================] - 86s 46ms/step - loss: 0.0270 - accuracy: 0.9900\n",
            "Epoch 26/50\n",
            "1875/1875 [==============================] - 86s 46ms/step - loss: 0.0280 - accuracy: 0.9902\n",
            "Epoch 27/50\n",
            "1875/1875 [==============================] - 86s 46ms/step - loss: 0.0234 - accuracy: 0.9916\n",
            "Epoch 28/50\n",
            "1875/1875 [==============================] - 86s 46ms/step - loss: 0.0263 - accuracy: 0.9909\n",
            "Epoch 29/50\n",
            "1875/1875 [==============================] - 86s 46ms/step - loss: 0.0250 - accuracy: 0.9911\n",
            "Epoch 30/50\n",
            "1875/1875 [==============================] - 86s 46ms/step - loss: 0.0238 - accuracy: 0.9917\n",
            "Epoch 31/50\n",
            "1875/1875 [==============================] - 86s 46ms/step - loss: 0.0233 - accuracy: 0.9920\n",
            "Epoch 32/50\n",
            "1875/1875 [==============================] - 85s 46ms/step - loss: 0.0208 - accuracy: 0.9923\n",
            "Epoch 33/50\n",
            "1875/1875 [==============================] - 85s 46ms/step - loss: 0.0222 - accuracy: 0.9921\n",
            "Epoch 34/50\n",
            "1875/1875 [==============================] - 86s 46ms/step - loss: 0.0220 - accuracy: 0.9924\n",
            "Epoch 35/50\n",
            "1875/1875 [==============================] - 86s 46ms/step - loss: 0.0218 - accuracy: 0.9929\n",
            "Epoch 36/50\n",
            "1875/1875 [==============================] - 86s 46ms/step - loss: 0.0215 - accuracy: 0.9933\n",
            "Epoch 37/50\n",
            "1875/1875 [==============================] - 86s 46ms/step - loss: 0.0212 - accuracy: 0.9930\n",
            "Epoch 38/50\n",
            "1875/1875 [==============================] - 86s 46ms/step - loss: 0.0176 - accuracy: 0.9941\n",
            "Epoch 39/50\n",
            "1875/1875 [==============================] - 86s 46ms/step - loss: 0.0188 - accuracy: 0.9933\n",
            "Epoch 40/50\n",
            "1875/1875 [==============================] - 86s 46ms/step - loss: 0.0238 - accuracy: 0.9924\n",
            "Epoch 41/50\n",
            "1875/1875 [==============================] - 86s 46ms/step - loss: 0.0195 - accuracy: 0.9933\n",
            "Epoch 42/50\n",
            "1875/1875 [==============================] - 86s 46ms/step - loss: 0.0177 - accuracy: 0.9939\n",
            "Epoch 43/50\n",
            "1875/1875 [==============================] - 86s 46ms/step - loss: 0.0209 - accuracy: 0.9934\n",
            "Epoch 44/50\n",
            "1875/1875 [==============================] - 86s 46ms/step - loss: 0.0167 - accuracy: 0.9947\n",
            "Epoch 45/50\n",
            "1875/1875 [==============================] - 86s 46ms/step - loss: 0.0197 - accuracy: 0.9934\n",
            "Epoch 46/50\n",
            "1875/1875 [==============================] - 86s 46ms/step - loss: 0.0208 - accuracy: 0.9934\n",
            "Epoch 47/50\n",
            "1875/1875 [==============================] - 86s 46ms/step - loss: 0.0156 - accuracy: 0.9953\n",
            "Epoch 48/50\n",
            "1875/1875 [==============================] - 86s 46ms/step - loss: 0.0175 - accuracy: 0.9943\n",
            "Epoch 49/50\n",
            "1875/1875 [==============================] - 86s 46ms/step - loss: 0.0163 - accuracy: 0.9946\n",
            "Epoch 50/50\n",
            "1875/1875 [==============================] - 86s 46ms/step - loss: 0.0174 - accuracy: 0.9951\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 1.0392 - accuracy: 0.9035\n",
            "[5.2798150e-22 3.3791972e-26 7.0537767e-31 5.0506914e-24 2.8194083e-20\n",
            " 4.2913874e-18 5.2904802e-37 5.1615076e-13 8.7734053e-25 1.0000000e+00]\n",
            "9\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "data = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(training_images, training_labels), (test_images, test_labels) = data.load_data()\n",
        "\n",
        "training_images = training_images.reshape(60000, 28, 28, 1)\n",
        "training_images = training_images / 255.0\n",
        "test_images = test_images.reshape(10000, 28, 28, 1)\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu',\n",
        "                           input_shape=(28, 28, 1)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=50)\n",
        "\n",
        "model.evaluate(test_images, test_labels)\n",
        "\n",
        "classifications = model.predict(test_images)\n",
        "print(classifications[0])\n",
        "print(test_labels[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgLzs_D0yu9i"
      },
      "source": [
        "### 3.4 A survey of convolutional networks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAdKljgy0mji",
        "outputId": "69e09d1a-04df-4da0-bb6d-66f69d6c3bca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 26, 26, 64)        640       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 13, 13, 64)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 11, 11, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 5, 5, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 1600)              0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 128)               204928    \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 243,786\n",
            "Trainable params: 243,786\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hl5lGzu0sc1"
      },
      "source": [
        "### 3.5 Building a CNN that discriminates between horses and humans"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7bgzqxs118k"
      },
      "source": [
        "#### Keras ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ED6WjgCX1_JJ"
      },
      "outputs": [],
      "source": [
        "import urllib.request\n",
        "import zipfile\n",
        "\n",
        "url = \"https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip\"\n",
        "file_name = \"horse-or-human.zip\"\n",
        "training_dir = 'horse-or-human/training/'\n",
        "urllib.request.urlretrieve(url, file_name)\n",
        "\n",
        "zip_ref = zipfile.ZipFile(file_name, 'r')\n",
        "zip_ref.extractall(training_dir)\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1mTpdkk4Mjh",
        "outputId": "e36bfbae-cf6f-4f62-e6f1-82cf0af6e09e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1027 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1/255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    training_dir,\n",
        "    target_size=(300, 300),\n",
        "    class_mode='binary'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fK1y_cYg4dbV"
      },
      "source": [
        "#### CNN architecture for horse and human datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y4BtC00p5OuB"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(16, (3, 3), activation='relu',\n",
        "                           input_shape=(300, 300, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QjuWZvtl9xam",
        "outputId": "9d81adef-42d3-4e21-f791-4fbdad3eaf0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_2 (Conv2D)           (None, 298, 298, 16)      448       \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 149, 149, 16)     0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 147, 147, 32)      4640      \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 73, 73, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 71, 71, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 35, 35, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 33, 33, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 16, 16, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 14, 14, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (None, 7, 7, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 3136)              0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 512)               1606144   \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 1)                 513       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,704,097\n",
            "Trainable params: 1,704,097\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bOKKxv6-CFv",
        "outputId": "8d5fbeb7-ed3f-4137-a84e-10f729d07cac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=RMSprop(lr=0.001),\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtrRaN2MDdi0",
        "outputId": "0807c5bf-76ec-42ec-d00e-3336a94bcfb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "33/33 [==============================] - 88s 3s/step - loss: 0.6692 - accuracy: 0.7186\n",
            "Epoch 2/15\n",
            "33/33 [==============================] - 87s 3s/step - loss: 0.1885 - accuracy: 0.9289\n",
            "Epoch 3/15\n",
            "33/33 [==============================] - 87s 3s/step - loss: 0.1656 - accuracy: 0.9426\n",
            "Epoch 4/15\n",
            "33/33 [==============================] - 87s 3s/step - loss: 0.0973 - accuracy: 0.9688\n",
            "Epoch 5/15\n",
            "33/33 [==============================] - 86s 3s/step - loss: 0.0700 - accuracy: 0.9776\n",
            "Epoch 6/15\n",
            "33/33 [==============================] - 87s 3s/step - loss: 0.0851 - accuracy: 0.9786\n",
            "Epoch 7/15\n",
            "33/33 [==============================] - 87s 3s/step - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 8/15\n",
            "33/33 [==============================] - 90s 3s/step - loss: 0.1481 - accuracy: 0.9776\n",
            "Epoch 9/15\n",
            "33/33 [==============================] - 89s 3s/step - loss: 0.1572 - accuracy: 0.9786\n",
            "Epoch 10/15\n",
            "33/33 [==============================] - 89s 3s/step - loss: 7.0092e-04 - accuracy: 1.0000\n",
            "Epoch 11/15\n",
            "33/33 [==============================] - 88s 3s/step - loss: 7.3481e-05 - accuracy: 1.0000\n",
            "Epoch 12/15\n",
            "33/33 [==============================] - 89s 3s/step - loss: 0.1345 - accuracy: 0.9776\n",
            "Epoch 13/15\n",
            "33/33 [==============================] - 88s 3s/step - loss: 0.0292 - accuracy: 0.9893\n",
            "Epoch 14/15\n",
            "33/33 [==============================] - 89s 3s/step - loss: 7.7902e-04 - accuracy: 1.0000\n",
            "Epoch 15/15\n",
            "33/33 [==============================] - 89s 3s/step - loss: 7.1390e-05 - accuracy: 1.0000\n"
          ]
        }
      ],
      "source": [
        "history = model.fit_generator(\n",
        "    train_generator,\n",
        "    epochs=15\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlfXJyqXDmMm"
      },
      "source": [
        "#### Validate the horse and human model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FMQkVMxPFs41"
      },
      "outputs": [],
      "source": [
        "validation_url = \"https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip\"\n",
        "\n",
        "validation_file_name = \"validation-horse-or-human.zip\"\n",
        "validation_dir = 'horse-or-human/validation/'\n",
        "urllib.request.urlretrieve(validation_url, validation_file_name)\n",
        "\n",
        "zip_ref = zipfile.ZipFile(validation_file_name, 'r')\n",
        "zip_ref.extractall(validation_dir)\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNMXZH2iKzAV",
        "outputId": "f987b1ae-37e6-4546-8c26-1c0997eb79aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 256 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "validation_datagen = ImageDataGenerator(rescale=1/255)\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size=(300, 300),\n",
        "    class_mode='binary'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BG2q2SpmLlsE",
        "outputId": "3cb86d10-afba-4bec-aa9b-70da5bf15f6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  after removing the cwd from sys.path.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "33/33 [==============================] - 96s 3s/step - loss: 6.1945e-06 - accuracy: 1.0000 - val_loss: 3.5698 - val_accuracy: 0.8477\n",
            "Epoch 2/15\n",
            "33/33 [==============================] - 95s 3s/step - loss: 7.0993e-07 - accuracy: 1.0000 - val_loss: 4.3638 - val_accuracy: 0.8477\n",
            "Epoch 3/15\n",
            "33/33 [==============================] - 108s 3s/step - loss: 0.3206 - accuracy: 0.9854 - val_loss: 4.3823 - val_accuracy: 0.7148\n",
            "Epoch 4/15\n",
            "33/33 [==============================] - 119s 4s/step - loss: 0.0073 - accuracy: 0.9990 - val_loss: 3.1375 - val_accuracy: 0.7969\n",
            "Epoch 5/15\n",
            "33/33 [==============================] - 100s 3s/step - loss: 1.7007e-04 - accuracy: 1.0000 - val_loss: 3.5395 - val_accuracy: 0.8125\n",
            "Epoch 6/15\n",
            "33/33 [==============================] - 96s 3s/step - loss: 9.0803e-06 - accuracy: 1.0000 - val_loss: 4.6531 - val_accuracy: 0.7852\n",
            "Epoch 7/15\n",
            "33/33 [==============================] - 94s 3s/step - loss: 1.1431e-06 - accuracy: 1.0000 - val_loss: 5.2026 - val_accuracy: 0.7812\n",
            "Epoch 8/15\n",
            "33/33 [==============================] - 94s 3s/step - loss: 8.9462e-07 - accuracy: 1.0000 - val_loss: 5.6355 - val_accuracy: 0.7812\n",
            "Epoch 9/15\n",
            "33/33 [==============================] - 94s 3s/step - loss: 7.6875e-08 - accuracy: 1.0000 - val_loss: 6.2867 - val_accuracy: 0.7812\n",
            "Epoch 10/15\n",
            "33/33 [==============================] - 94s 3s/step - loss: 9.9971e-09 - accuracy: 1.0000 - val_loss: 6.2936 - val_accuracy: 0.7969\n",
            "Epoch 11/15\n",
            "33/33 [==============================] - 94s 3s/step - loss: 4.3625e-09 - accuracy: 1.0000 - val_loss: 6.9198 - val_accuracy: 0.7969\n",
            "Epoch 12/15\n",
            "33/33 [==============================] - 94s 3s/step - loss: 0.1901 - accuracy: 0.9951 - val_loss: 3.3524 - val_accuracy: 0.8711\n",
            "Epoch 13/15\n",
            "33/33 [==============================] - 94s 3s/step - loss: 1.2251e-05 - accuracy: 1.0000 - val_loss: 3.5284 - val_accuracy: 0.8711\n",
            "Epoch 14/15\n",
            "33/33 [==============================] - 94s 3s/step - loss: 4.9839e-06 - accuracy: 1.0000 - val_loss: 3.6955 - val_accuracy: 0.8711\n",
            "Epoch 15/15\n",
            "33/33 [==============================] - 94s 3s/step - loss: 1.6716e-06 - accuracy: 1.0000 - val_loss: 3.9553 - val_accuracy: 0.8633\n"
          ]
        }
      ],
      "source": [
        "history = model.fit_generator(\n",
        "    train_generator,\n",
        "    epochs=15,\n",
        "    validation_data=validation_generator\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucDqB4JmL2wY"
      },
      "source": [
        "#### Testing Horse and Human Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iuBsY1PsMIuY",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8e6d08d2-7646-41a7-951a-a9ac22c8204f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-7617bb9c-29fd-4499-a92c-d95528eac67e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-7617bb9c-29fd-4499-a92c-d95528eac67e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving face-5084530__340.jpg to face-5084530__340 (2).jpg\n",
            "Saving man-2785071__340.jpg to man-2785071__340.jpg\n",
            "Saving male-4494491__340.jpg to male-4494491__340.jpg\n",
            "Saving grimace-388987__340.jpg to grimace-388987__340.jpg\n",
            "Saving beautiful-2405131__340.jpg to beautiful-2405131__340.jpg\n",
            "Saving horse-2196755__340.jpg to horse-2196755__340.jpg\n",
            "Saving horses-1414889__340.jpg to horses-1414889__340.jpg\n",
            "Saving white-horse-3010129__340.jpg to white-horse-3010129__340.jpg\n",
            "Saving woman-3551832__480.jpg to woman-3551832__480.jpg\n",
            "Saving istockphoto-1327505110-170667a.jpg to istockphoto-1327505110-170667a.jpg\n",
            "Saving istockphoto-1334485590-170667a.jpg to istockphoto-1334485590-170667a (1).jpg\n",
            "[[0.]]\n",
            "[0.]\n",
            "face-5084530__340.jpgis a horse\n",
            "[[0.]]\n",
            "[0.]\n",
            "man-2785071__340.jpgis a horse\n",
            "[[1.]]\n",
            "[1.]\n",
            "male-4494491__340.jpgis a human\n",
            "[[0.]]\n",
            "[0.]\n",
            "grimace-388987__340.jpgis a horse\n",
            "[[0.]]\n",
            "[0.]\n",
            "beautiful-2405131__340.jpgis a horse\n",
            "[[0.]]\n",
            "[0.]\n",
            "horse-2196755__340.jpgis a horse\n",
            "[[0.]]\n",
            "[0.]\n",
            "horses-1414889__340.jpgis a horse\n",
            "[[0.]]\n",
            "[0.]\n",
            "white-horse-3010129__340.jpgis a horse\n",
            "[[0.]]\n",
            "[0.]\n",
            "woman-3551832__480.jpgis a horse\n",
            "[[0.]]\n",
            "[0.]\n",
            "istockphoto-1327505110-170667a.jpgis a horse\n",
            "[[0.]]\n",
            "[0.]\n",
            "istockphoto-1334485590-170667a.jpgis a horse\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from google.colab import files\n",
        "from keras.preprocessing import image\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "\n",
        "  # predicting images\n",
        "  path = '/content/' + fn\n",
        "  img = image.load_img(path, target_size=(300, 300))\n",
        "  x = image.img_to_array(img)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "\n",
        "  image_tensor = np.vstack([x])\n",
        "  classes = model.predict(image_tensor)\n",
        "  print(classes)\n",
        "  print(classes[0])\n",
        "  if classes[0]>0.5:\n",
        "    print(fn + \"is a human\")\n",
        "  else:\n",
        "    print(fn + \"is a horse\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.6 Image Augmentation"
      ],
      "metadata": {
        "id": "a_TD6tskYVTG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "hQs8BYXMY0My"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "AI and Machine Learning for Coders.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM1oeBJFgiZ3Gi8Umqgfm6P",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}